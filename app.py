from flask import Flask, render_template, jsonify, request, make_response, send_from_directory
from bs4 import BeautifulSoup
from flask_cors import CORS
import re
import cloudscraper
import logging
from datetime import datetime, timedelta
import threading
import time
import random
from urllib.parse import urlparse

app = Flask(__name__)
CORS(app)

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

video_cache = {}
CACHE_DURATION = 0  # 5 minutes cache
REFRESH_INTERVAL = 1800  # 30 minutes auto-refresh
MAX_RETRIES = 3

TARGET_SITES = [
    {"name": "Main Site", "url": "https://www.xv-ru.com/?k=sissy&sort=random&typef=gay"},
    {"name": "Gay Videos", "url": "https://www.xv-ru.com/?k=gay&sort=random&typef=gay"},
    {"name": "Trans Videos", "url": "https://www.xv-ru.com/?k=trans&sort=random&typef=trans"},
    {"name": "Lesbian Videos", "url": "https://www.xv-ru.com/?k=lesbian&sort=random&typef=lesbian"},
    {"name": "Bisexual Videos", "url": "https://www.xv-ru.com/?k=bisexual&sort=random&typef=bisexual"}
]

def parse_main_page(page=0, site_index=0):
    """–ü–∞—Ä—Å–∏–Ω–≥ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø–∞–≥–∏–Ω–∞—Ü–∏–∏ –∏ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–∞–π—Ç–æ–≤"""
    try:
        print("="*60)

        # –í—ã–±–∏—Ä–∞–µ–º —Å–∞–π—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
        site_url = TARGET_SITES[site_index]["url"]

        # –§–æ—Ä–º–∏—Ä—É–µ–º URL —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        if page > 0:
            url = f"{site_url}&p={page}"
        else:
            url = site_url

        print(f"–ó–∞–ø—Ä–æ—Å –∫ {url}")

        # –°–æ–∑–¥–∞–µ–º scraper —Å —Å–ª—É—á–∞–π–Ω—ã–º–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –∑–∞—â–∏—Ç—ã
        headers = {
            'User-Agent': random.choice([
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            ]),
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
        }

        scraper = cloudscraper.create_scraper()
        response = scraper.get(url, headers=headers, timeout=15)

        print(f"–°—Ç–∞—Ç—É—Å: {response.status_code}")

        soup = BeautifulSoup(response.content, 'html.parser')
        videos = []

        # –ò—â–µ–º –≤—Å–µ –≤–∏–¥–µ–æ –±–ª–æ–∫–∏
        video_blocks = soup.find_all('div', class_='thumb-block')
        print(f"‚úì –ù–∞–π–¥–µ–Ω–æ {len(video_blocks)} –≤–∏–¥–µ–æ –±–ª–æ–∫–æ–≤")

        for block in video_blocks:
            try:
                # –°—Å—ã–ª–∫–∞ –Ω–∞ –≤–∏–¥–µ–æ
                link = block.find('a', href=re.compile(r'/video'))
                if not link:
                    continue

                href = link.get('href', '')

                # ID –∏–∑ URL
                video_id_match = re.search(r'/video\.([a-z0-9]+)/', href)
                if not video_id_match:
                    continue

                video_id = video_id_match.group(1)

                # –ù–ê–ó–í–ê–ù–ò–ï –∏–∑ title –∞—Ç—Ä–∏–±—É—Ç–∞ —Å—Å—ã–ª–∫–∏ –≤ thumb-under
                title_link = block.find('p', class_='title')
                title = ""
                if title_link:
                    title_a = title_link.find('a')
                    if title_a:
                        # –ë–µ—Ä–µ–º title –∞—Ç—Ä–∏–±—É—Ç
                        title = title_a.get('title', '')
                        # –£–±–∏—Ä–∞–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑ title –µ—Å–ª–∏ –µ—Å—Ç—å
                        title = re.sub(r'\s*<span class="duration">.*?</span>\s*$', '', title)

                # –ï—Å–ª–∏ title –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–±—É–µ–º —Ç–µ–∫—Å—Ç
                if not title:
                    if title_link:
                        title_a = title_link.find('a')
                        if title_a:
                            title_text = title_a.get_text(strip=True)
                            # –£–±–∏—Ä–∞–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑ –∫–æ–Ω—Ü–∞
                            title = re.sub(r'\s+\d+\s+(–º–∏–Ω\.|—Å–µ–∫\.|—á\.).*$', '', title_text)

                if not title:
                    title = f"Video {video_id}"

                # –ü–æ–ª–Ω—ã–π URL
                video_url = site_url.split('?')[0].rstrip('/') + href if href.startswith('/') else href

                # Thumbnail
                thumbnail = ""
                img = block.find('img')
                if img:
                    thumbnail = (img.get('data-src') or
                                img.get('data-thumb_url') or
                                img.get('src') or "")

                    if thumbnail:
                        # protocol-relative (//example.com/img.jpg)
                        if thumbnail.startswith('//'):
                            thumbnail = 'https:' + thumbnail
                        # root-relative (/images/img.jpg)
                        elif thumbnail.startswith('/'):
                            base = site_url.split('?')[0].rstrip('/')
                            thumbnail = base + thumbnail
                        # relative (images/img.jpg)
                        elif not thumbnail.startswith('http'):
                            base = f"{urlparse(site_url).scheme}://{urlparse(site_url).netloc}"
                            thumbnail = base.rstrip('/') + '/' + thumbnail

                # –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                duration = "00:00"
                dur_span = block.find('span', class_='duration')
                if dur_span:
                    duration = dur_span.get_text(strip=True)

                # –ü–æ–ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤
                views = "0"
                views_elem = block.find('span', class_='views')
                if views_elem:
                    views_text = views_elem.get_text(strip=True)
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤
                    views_match = re.search(r'(\d+(?:\.\d+)?[KMB]?)', views_text)
                    if views_match:
                        views = views_match.group(1)

                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∞–π—Ç–µ
                videos.append({
                    'id': video_id,
                    'title': title.strip(),
                    'page_url': video_url,
                    'thumbnail': thumbnail,
                    'duration': duration,
                    'views': views,
                    'source_site': TARGET_SITES[site_index]["name"],
                    'added_at': datetime.utcnow().isoformat()
                })

                print(f"‚úì {video_id}: {title[:80]}")

            except Exception as e:
                print(f"‚ö† –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –±–ª–æ–∫–∞: {e}")
                continue

        print(f"–ò–¢–û–ì–û: {len(videos)} –≤–∏–¥–µ–æ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page} —Å {TARGET_SITES[site_index]['name']}")
        return videos

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return []

def get_video_embed_url(video_id):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ iframe URL –¥–ª—è –≤—Å—Ç—Ä–∞–∏–≤–∞–Ω–∏—è"""
    embed_url = f"https://www.xv-ru.com/embedframe/{video_id}"
    print(f"‚úì Embed URL: {embed_url}")

    return {
        'type': 'iframe',
        'url': embed_url
    }

def auto_refresh_cache():
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–µ—à–∞"""
    while True:
        time.sleep(REFRESH_INTERVAL)
        print("\nüîÑ –ê–≤—Ç–æ–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–µ—à–∞...")
        for site_index in range(len(TARGET_SITES)):
            parse_main_page(0, site_index)

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/logo.png')
def logo_png():
    # Serve the logo file located in the project root
    import os
    root = os.getcwd()
    return send_from_directory(root, 'logo.png')

@app.route('/api/videos')
def get_videos():
    import time

    # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∑–∞–ø—Ä–æ—Å–∞
    page = request.args.get('page', 0, type=int)
    site_index = request.args.get('site', 0, type=int)
    sort_by = request.args.get('sort', 'random')  # random, date, views

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –∏–Ω–¥–µ–∫—Å–∞ —Å–∞–π—Ç–∞
    if site_index >= len(TARGET_SITES):
        site_index = 0

    cache_key = f'page_{page}_site_{site_index}'
    current_time = time.time()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    if cache_key not in video_cache:
        video_cache[cache_key] = {'data': [], 'timestamp': 0}

    if current_time - video_cache[cache_key]['timestamp'] > CACHE_DURATION or not video_cache[cache_key]['data']:
        print(f"\nüîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–µ—à–∞ –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page}, —Å–∞–π—Ç {TARGET_SITES[site_index]['name']}...")
        video_cache[cache_key]['data'] = parse_main_page(page, site_index)
        video_cache[cache_key]['timestamp'] = current_time
    else:
        remaining = int(CACHE_DURATION - (current_time - video_cache[cache_key]['timestamp']))
        print(f"‚úì –ö–µ—à —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page} —Å–∞–π—Ç–∞ {TARGET_SITES[site_index]['name']} ({remaining} —Å–µ–∫, –≤–∏–¥–µ–æ: {len(video_cache[cache_key]['data'])})")

    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –≤–∏–¥–µ–æ
    videos = video_cache[cache_key]['data'].copy()

    if sort_by == 'date':
        videos.sort(key=lambda x: x.get('added_at', ''), reverse=True)
    elif sort_by == 'views':
        def extract_views(views_str):
            if 'K' in views_str:
                return float(views_str.replace('K', '')) * 1000
            elif 'M' in views_str:
                return float(views_str.replace('M', '')) * 1000000
            elif 'B' in views_str:
                return float(views_str.replace('B', '')) * 1000000000
            else:
                return int(views_str) if views_str.isdigit() else 0

        videos.sort(key=lambda x: extract_views(x.get('views', '0')), reverse=True)
    elif sort_by == 'random':
        random.shuffle(videos)

    resp = make_response(jsonify({
        'videos': videos,
        'page': page,
        'total': len(videos),
        'site_info': TARGET_SITES[site_index],
        'sort_by': sort_by
    }))
    resp.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
    resp.headers['Pragma'] = 'no-cache'
    resp.headers['Expires'] = '0'
    return resp

@app.route('/api/sites')
def get_sites():
    """API endpoint –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å–∞–π—Ç–æ–≤"""
    return jsonify(TARGET_SITES)

@app.route('/api/video/<video_id>')
def get_video_details(video_id):
    # –ò—â–µ–º –≤–∏–¥–µ–æ –≤ –∫–µ—à–µ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
    video = None
    for cache_key in video_cache:
        if video_cache[cache_key]['data']:
            video = next((v for v in video_cache[cache_key]['data'] if v['id'] == video_id), None)
            if video:
                break

    # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –∫–µ—à–µ, –ø–∞—Ä—Å–∏–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –∫–∞–∂–¥–æ–≥–æ —Å–∞–π—Ç–∞
    if not video:
        for site_index in range(len(TARGET_SITES)):
            videos = parse_main_page(0, site_index)
            video = next((v for v in videos if v['id'] == video_id), None)
            if video:
                break

    if video:
        embed_data = get_video_embed_url(video_id)
        video['embed'] = embed_data
        resp = make_response(jsonify(video))
        resp.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
        resp.headers['Pragma'] = 'no-cache'
        resp.headers['Expires'] = '0'
        return resp

    resp = make_response(jsonify({'error': 'Video not found'}), 404)
    resp.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
    resp.headers['Pragma'] = 'no-cache'
    resp.headers['Expires'] = '0'
    return resp

@app.route('/api/refresh')
def refresh():
    # –û—á–∏—â–∞–µ–º –≤–µ—Å—å –∫–µ—à
    video_cache.clear()
    videos = []

    # –ü–∞—Ä—Å–∏–º –≤—Å–µ —Å–∞–π—Ç—ã
    for site_index in range(len(TARGET_SITES)):
        videos.extend(parse_main_page(0, site_index))

    # –î–æ–±–∞–≤–ª—è–µ–º embed –¥–ª—è –ø–µ—Ä–≤—ã—Ö 3 –≤–∏–¥–µ–æ
    for video in videos[:3]:
        video['embed'] = get_video_embed_url(video['id'])

    resp = make_response(jsonify({
        'total': len(videos),
        'videos': videos[:3],
        'message': f'Cleared cache and refreshed {len(videos)} videos from {len(TARGET_SITES)} sites'
    }))
    resp.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
    resp.headers['Pragma'] = 'no-cache'
    resp.headers['Expires'] = '0'
    return resp

@app.route('/api/search')
def search_videos():
    """–ü–æ–∏—Å–∫ –≤–∏–¥–µ–æ –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É"""
    query = request.args.get('q', '').strip().lower()
    if not query:
        return jsonify({'error': 'Query parameter required'}), 400

    # –ò—â–µ–º –≤–∏–¥–µ–æ –≤–æ –≤—Å–µ—Ö –∑–∞–∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    results = []
    for cache_key in video_cache:
        if video_cache[cache_key]['data']:
            for video in video_cache[cache_key]['data']:
                if query in video['title'].lower() or query in video['id'].lower():
                    results.append(video)

    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ –∫–µ—à–µ, –¥–µ–ª–∞–µ–º –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫
    if not results:
        for site_index in range(len(TARGET_SITES)):
            videos = parse_main_page(0, site_index)
            for video in videos:
                if query in video['title'].lower() or query in video['id'].lower():
                    results.append(video)

    return jsonify({
        'query': query,
        'results': results[:20],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        'total': len(results)
    })

@app.route('/api/stats')
def get_stats():
    """API endpoint –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
    total_videos = 0
    cached_pages = len(video_cache)

    for cache_key in video_cache:
        total_videos += len(video_cache[cache_key]['data'])

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
    last_update = 0
    for cache_key in video_cache:
        if video_cache[cache_key]['timestamp'] > last_update:
            last_update = video_cache[cache_key]['timestamp']

    last_update_str = datetime.fromtimestamp(last_update).strftime('%Y-%m-%d %H:%M:%S') if last_update > 0 else 'Never'

    return jsonify({
        'total_cached_videos': total_videos,
        'cached_pages': cached_pages,
        'last_update': last_update_str,
        'cache_duration': CACHE_DURATION,
        'sites_count': len(TARGET_SITES)
    })

@app.route('/api/trending')
def get_trending():
    """API endpoint –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–æ–≤—ã—Ö –≤–∏–¥–µ–æ"""
    trending_videos = []

    # –ü–æ–ª—É—á–∞–µ–º –≤–∏–¥–µ–æ –∏–∑ –≤—Å–µ—Ö —Å–∞–π—Ç–æ–≤
    for site_index in range(len(TARGET_SITES)):
        if f'page_0_site_{site_index}' in video_cache:
            videos = video_cache[f'page_0_site_{site_index}']['data']
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤
            def extract_views(views_str):
                if 'K' in views_str:
                    return float(views_str.replace('K', '')) * 1000
                elif 'M' in views_str:
                    return float(views_str.replace('M', '')) * 1000000
                elif 'B' in views_str:
                    return float(views_str.replace('B', '')) * 1000000000
                else:
                    return int(views_str) if views_str.isdigit() else 0

            videos.sort(key=lambda x: extract_views(x.get('views', '0')), reverse=True)
            trending_videos.extend(videos[:5])  # –ë–µ—Ä–µ–º —Ç–æ–ø 5 —Å –∫–∞–∂–¥–æ–≥–æ —Å–∞–π—Ç–∞

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø 20 —Å–∞–º—ã—Ö –ø—Ä–æ—Å–º–∞—Ç—Ä–∏–≤–∞–µ–º—ã—Ö –≤–∏–¥–µ–æ
    trending_videos.sort(key=lambda x: extract_views(x.get('views', '0')), reverse=True)

    return jsonify({
        'trending_videos': trending_videos[:20],
        'total': len(trending_videos)
    })

if __name__ == '__main__':
    print("="*60)
    print("üöÄ http://localhost:5000")
    print("üîÑ http://localhost:5000/api/refresh")
    print("üîç http://localhost:5000/api/search?q=term")
    print("üìä http://localhost:5000/api/stats")
    print("üåê http://localhost:5000/api/sites")
    print("üî• http://localhost:5000/api/trending")
    print("="*60)

    # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–≤—Ç–æ–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–µ—à–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
    refresh_thread = threading.Thread(target=auto_refresh_cache, daemon=True)
    refresh_thread.start()

    app.run(debug=True, port=5000)
